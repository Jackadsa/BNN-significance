{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import energyflow\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading QG_jets.npz from https://www.dropbox.com/s/fclsl7pukcpobsb/QG_jets.npz?dl=1 to /home/jack/.energyflow/datasets\n"
     ]
    }
   ],
   "source": [
    "X, Y = energyflow.datasets.qg_jets.load(num_data=100000, generator='pythia', pad=True, with_bc=False, cache_dir='~/.energyflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess by centering jets and normalizing pts\n",
    "for x in X:\n",
    "    mask = x[:,0] > 0\n",
    "    yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "    x[mask,1:3] -= yphi_avg\n",
    "    x[mask,0] /= x[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess PIDs so they are O(1) or less\n",
    "X[:,:,3] = X[:,:,3] / 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparticles = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_29 (InputLayer)        (None, 139, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 139, 16)           80        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_32 (Averag (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 369\n",
      "Trainable params: 369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(nparticles,4))\n",
    "layer = keras.layers.Conv1D(16,1,padding=\"same\",activation=\"relu\")(inputs)\n",
    "layer = keras.layers.AveragePooling1D(pool_size = nparticles, padding=\"same\")(layer)\n",
    "layer = keras.layers.Flatten()(layer)\n",
    "layer = keras.layers.Dense(16,activation=\"relu\")(layer)\n",
    "output = keras.layers.Dense(1,activation=\"sigmoid\")(layer)\n",
    "model = keras.Model(inputs=inputs, outputs=output)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "             loss = 'binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 15s 147us/sample - loss: 0.5624 - acc: 0.7236\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 12s 120us/sample - loss: 0.5156 - acc: 0.7507\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 13s 128us/sample - loss: 0.4984 - acc: 0.7623\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 15s 148us/sample - loss: 0.4866 - acc: 0.7710\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 14s 137us/sample - loss: 0.4802 - acc: 0.7750\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 12s 124us/sample - loss: 0.4774 - acc: 0.7770\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 13s 135us/sample - loss: 0.4754 - acc: 0.7783\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 13s 125us/sample - loss: 0.4742 - acc: 0.7806\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 11s 114us/sample - loss: 0.4732 - acc: 0.7810\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 11s 114us/sample - loss: 0.4723 - acc: 0.7814\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X,Y,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9889244 ],\n",
       "       [0.9857632 ],\n",
       "       [0.12990975],\n",
       "       [0.6508647 ],\n",
       "       [0.7963798 ],\n",
       "       [0.22441   ],\n",
       "       [0.9892951 ],\n",
       "       [0.8941284 ],\n",
       "       [0.7492796 ],\n",
       "       [0.98642755],\n",
       "       [0.9342357 ],\n",
       "       [0.19584006],\n",
       "       [0.07013935],\n",
       "       [0.27346027],\n",
       "       [0.3341374 ],\n",
       "       [0.9007114 ],\n",
       "       [0.200127  ],\n",
       "       [0.29861665],\n",
       "       [0.6812169 ],\n",
       "       [0.27042848],\n",
       "       [0.06506029],\n",
       "       [0.9335626 ],\n",
       "       [0.9340154 ],\n",
       "       [0.41713715],\n",
       "       [0.7390985 ],\n",
       "       [0.40384182],\n",
       "       [0.66093755],\n",
       "       [0.43255898],\n",
       "       [0.4321254 ],\n",
       "       [0.77069855],\n",
       "       [0.3253877 ],\n",
       "       [0.18557853],\n",
       "       [0.28337917],\n",
       "       [0.74087775],\n",
       "       [0.193587  ],\n",
       "       [0.25558156],\n",
       "       [0.32523674],\n",
       "       [0.800222  ],\n",
       "       [0.88683546],\n",
       "       [0.24996164],\n",
       "       [0.3011129 ],\n",
       "       [0.1338093 ],\n",
       "       [0.4137681 ],\n",
       "       [0.9822666 ],\n",
       "       [0.8969711 ],\n",
       "       [0.35345945],\n",
       "       [0.9158151 ],\n",
       "       [0.8909861 ],\n",
       "       [0.24465019],\n",
       "       [0.25857508],\n",
       "       [0.7733901 ],\n",
       "       [0.92178226],\n",
       "       [0.23246786],\n",
       "       [0.1522162 ],\n",
       "       [0.32465768],\n",
       "       [0.23049554],\n",
       "       [0.8369522 ],\n",
       "       [0.9656184 ],\n",
       "       [0.23134384],\n",
       "       [0.9371846 ],\n",
       "       [0.9491572 ],\n",
       "       [0.69372666],\n",
       "       [0.8408618 ],\n",
       "       [0.32210213],\n",
       "       [0.82652503],\n",
       "       [0.5141905 ],\n",
       "       [0.13215962],\n",
       "       [0.7771083 ],\n",
       "       [0.23441124],\n",
       "       [0.85276306],\n",
       "       [0.94353235],\n",
       "       [0.90990895],\n",
       "       [0.97876716],\n",
       "       [0.82788837],\n",
       "       [0.14992008],\n",
       "       [0.6971404 ],\n",
       "       [0.3296994 ],\n",
       "       [0.5157892 ],\n",
       "       [0.87587345],\n",
       "       [0.35411152],\n",
       "       [0.13298339],\n",
       "       [0.19692114],\n",
       "       [0.32996005],\n",
       "       [0.30144083],\n",
       "       [0.27128455],\n",
       "       [0.14198443],\n",
       "       [0.9088499 ],\n",
       "       [0.38022983],\n",
       "       [0.96192014],\n",
       "       [0.64489466],\n",
       "       [0.57735324],\n",
       "       [0.32341546],\n",
       "       [0.667203  ],\n",
       "       [0.43439743],\n",
       "       [0.31731686],\n",
       "       [0.95717496],\n",
       "       [0.39823106],\n",
       "       [0.14163706],\n",
       "       [0.15458839],\n",
       "       [0.04011991]], dtype=float32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BNN\n",
    "\n",
    "Fucked it up so far, need to fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        (None, 139, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_flipout_20 (Conv1DFli (None, 139, 16)           144       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_22 (Averag (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_flipout_26 (DenseFlipo (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_flipout_27 (DenseFlipo (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "inputs = keras.Input(shape=(nparticles,4))\n",
    "layer = tfp.layers.Convolution1DFlipout(16,1,padding=\"same\",activation=\"relu\")(inputs)\n",
    "#layer = tfp.layers.Convolution1DFlipout(16,1,padding=\"same\",activation=\"relu\")(layer)\n",
    "layer = keras.layers.AveragePooling1D(pool_size = nparticles, padding=\"same\")(layer)\n",
    "layer = keras.layers.Flatten()(layer)\n",
    "layer = tfp.layers.DenseFlipout(16,activation=\"relu\")(layer)\n",
    "output = tfp.layers.DenseFlipout(1,activation=\"sigmoid\")(layer)\n",
    "model = keras.Model(inputs=inputs, outputs=output)\n",
    "model.summary()\n",
    "\n",
    "def custom_loss(y_true,y_pred):\n",
    "\n",
    "    neg_log_likelihood = keras.losses.binary_crossentropy(\n",
    "        y_true,\n",
    "        y_pred\n",
    "    )\n",
    "    kl = sum(model.losses)/batch_size\n",
    "    return neg_log_likelihood + kl\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss = custom_loss,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_flipout_29 (Conv1DFli (None, 139, 16)           144       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_31 (Averag (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_flipout_44 (DenseFlipo (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_flipout_45 (DenseFlipo (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "model = keras.Sequential([\n",
    "    tfp.layers.Convolution1DFlipout(16,1,padding=\"same\",activation=\"relu\",input_shape=(nparticles,4)),\n",
    "    keras.layers.AveragePooling1D(pool_size = nparticles, padding=\"same\"),\n",
    "    keras.layers.Flatten(),\n",
    "    tfp.layers.DenseFlipout(16,activation=\"relu\"),\n",
    "    tfp.layers.DenseFlipout(1,activation=\"relu\")\n",
    "])\n",
    "# model.build(input_shape=(None,nparticles,4))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "def custom_loss2(y_true,y_pred):\n",
    "\n",
    "    neg_log_likelihood = keras.losses.binary_crossentropy(\n",
    "        y_true,\n",
    "        y_pred\n",
    "    )\n",
    "    kl = sum(model.losses)/10000\n",
    "    return neg_log_likelihood + kl\n",
    "\n",
    "\n",
    "logits = model(images)\n",
    "labels_distribution = tfd.Categorical(logits=logits)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss = custom_loss2,\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'sequential_8_1/dense_flipout_45/Sigmoid:0' shape=(100, 1) dtype=float32>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 688.9618 - acc: 0.5013\n",
      "Epoch 2/100\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 389.4827 - acc: 0.4992\n",
      "Epoch 3/100\n",
      "100000/100000 [==============================] - 8s 77us/sample - loss: 156.5932 - acc: 0.4970\n",
      "Epoch 4/100\n",
      "100000/100000 [==============================] - 8s 82us/sample - loss: 34.2414 - acc: 0.4892\n",
      "Epoch 5/100\n",
      "100000/100000 [==============================] - 7s 71us/sample - loss: 3.1962 - acc: 0.5046\n",
      "Epoch 6/100\n",
      "100000/100000 [==============================] - 7s 72us/sample - loss: 0.7273 - acc: 0.5119\n",
      "Epoch 7/100\n",
      "100000/100000 [==============================] - 8s 78us/sample - loss: 0.6933 - acc: 0.4948\n",
      "Epoch 8/100\n",
      "100000/100000 [==============================] - 7s 71us/sample - loss: 0.6933 - acc: 0.4986\n",
      "Epoch 9/100\n",
      "100000/100000 [==============================] - 8s 79us/sample - loss: 0.6931 - acc: 0.5051\n",
      "Epoch 10/100\n",
      "100000/100000 [==============================] - 8s 82us/sample - loss: 0.6932 - acc: 0.4973\n",
      "Epoch 11/100\n",
      "100000/100000 [==============================] - 8s 75us/sample - loss: 0.6932 - acc: 0.5018\n",
      "Epoch 12/100\n",
      "100000/100000 [==============================] - 8s 77us/sample - loss: 0.6932 - acc: 0.4986\n",
      "Epoch 13/100\n",
      "100000/100000 [==============================] - 8s 78us/sample - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 14/100\n",
      "100000/100000 [==============================] - 7s 74us/sample - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 15/100\n",
      "100000/100000 [==============================] - 7s 70us/sample - loss: 0.6932 - acc: 0.4964\n",
      "Epoch 16/100\n",
      "100000/100000 [==============================] - 8s 81us/sample - loss: 0.6932 - acc: 0.4972\n",
      "Epoch 17/100\n",
      "100000/100000 [==============================] - 8s 79us/sample - loss: 0.6932 - acc: 0.5014\n",
      "Epoch 18/100\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.6932 - acc: 0.4995\n",
      "Epoch 19/100\n",
      "100000/100000 [==============================] - 10s 97us/sample - loss: 0.6932 - acc: 0.4992\n",
      "Epoch 20/100\n",
      "100000/100000 [==============================] - 10s 100us/sample - loss: 0.6932 - acc: 0.4966\n",
      "Epoch 21/100\n",
      "100000/100000 [==============================] - 9s 87us/sample - loss: 0.6932 - acc: 0.4976\n",
      "Epoch 22/100\n",
      "100000/100000 [==============================] - 8s 82us/sample - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 23/100\n",
      "100000/100000 [==============================] - 8s 83us/sample - loss: 0.6932 - acc: 0.5010\n",
      "Epoch 24/100\n",
      "100000/100000 [==============================] - 8s 83us/sample - loss: 0.6932 - acc: 0.5004\n",
      "Epoch 25/100\n",
      "100000/100000 [==============================] - 8s 83us/sample - loss: 0.6932 - acc: 0.4994\n",
      "Epoch 26/100\n",
      "100000/100000 [==============================] - 8s 83us/sample - loss: 0.6932 - acc: 0.4970\n",
      "Epoch 27/100\n",
      "100000/100000 [==============================] - 8s 75us/sample - loss: 0.6932 - acc: 0.4952\n",
      "Epoch 28/100\n",
      "100000/100000 [==============================] - 7s 69us/sample - loss: 0.6932 - acc: 0.4982\n",
      "Epoch 29/100\n",
      "100000/100000 [==============================] - 9s 87us/sample - loss: 0.6932 - acc: 0.4984\n",
      "Epoch 30/100\n",
      "100000/100000 [==============================] - 11s 113us/sample - loss: 0.6932 - acc: 0.4975\n",
      "Epoch 31/100\n",
      "100000/100000 [==============================] - 10s 104us/sample - loss: 0.6932 - acc: 0.5005\n",
      "Epoch 32/100\n",
      "100000/100000 [==============================] - 9s 87us/sample - loss: 0.6932 - acc: 0.4989\n",
      "Epoch 33/100\n",
      "100000/100000 [==============================] - 9s 85us/sample - loss: 0.6932 - acc: 0.4985\n",
      "Epoch 34/100\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.6932 - acc: 0.4974\n",
      "Epoch 35/100\n",
      "100000/100000 [==============================] - 11s 108us/sample - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 36/100\n",
      "100000/100000 [==============================] - 11s 109us/sample - loss: 0.6932 - acc: 0.5009\n",
      "Epoch 37/100\n",
      "100000/100000 [==============================] - 11s 106us/sample - loss: 0.6932 - acc: 0.4995\n",
      "Epoch 38/100\n",
      "100000/100000 [==============================] - 9s 89us/sample - loss: 0.6932 - acc: 0.4977\n",
      "Epoch 39/100\n",
      "100000/100000 [==============================] - 12s 120us/sample - loss: 0.6932 - acc: 0.5002\n",
      "Epoch 40/100\n",
      "100000/100000 [==============================] - 11s 106us/sample - loss: 0.6932 - acc: 0.4969\n",
      "Epoch 41/100\n",
      "100000/100000 [==============================] - 7s 72us/sample - loss: 0.6931 - acc: 0.5009\n",
      "Epoch 42/100\n",
      "100000/100000 [==============================] - 7s 70us/sample - loss: 0.6932 - acc: 0.4984\n",
      "Epoch 43/100\n",
      "100000/100000 [==============================] - 7s 69us/sample - loss: 0.6932 - acc: 0.5001\n",
      "Epoch 44/100\n",
      "100000/100000 [==============================] - 10s 99us/sample - loss: 0.6932 - acc: 0.4992\n",
      "Epoch 45/100\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.6932 - acc: 0.4968\n",
      "Epoch 46/100\n",
      "100000/100000 [==============================] - 11s 115us/sample - loss: 0.6932 - acc: 0.5013\n",
      "Epoch 47/100\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.6932 - acc: 0.4971\n",
      "Epoch 48/100\n",
      "100000/100000 [==============================] - 8s 83us/sample - loss: 0.6932 - acc: 0.5007\n",
      "Epoch 49/100\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.6932 - acc: 0.4984\n",
      "Epoch 50/100\n",
      "100000/100000 [==============================] - 12s 118us/sample - loss: 0.6932 - acc: 0.5002\n",
      "Epoch 51/100\n",
      "100000/100000 [==============================] - 8s 76us/sample - loss: 0.6932 - acc: 0.5002\n",
      "Epoch 52/100\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.6932 - acc: 0.4995\n",
      "Epoch 53/100\n",
      "100000/100000 [==============================] - 18s 178us/sample - loss: 0.6932 - acc: 0.4979\n",
      "Epoch 54/100\n",
      "100000/100000 [==============================] - 9s 95us/sample - loss: 0.6932 - acc: 0.4997\n",
      "Epoch 55/100\n",
      "100000/100000 [==============================] - 8s 83us/sample - loss: 0.6932 - acc: 0.5013\n",
      "Epoch 56/100\n",
      "100000/100000 [==============================] - 9s 86us/sample - loss: 0.6932 - acc: 0.5009\n",
      "Epoch 57/100\n",
      "100000/100000 [==============================] - 8s 81us/sample - loss: 0.6932 - acc: 0.4999\n",
      "Epoch 58/100\n",
      "100000/100000 [==============================] - 14s 142us/sample - loss: 0.6932 - acc: 0.4980\n",
      "Epoch 59/100\n",
      "100000/100000 [==============================] - 12s 116us/sample - loss: 0.6932 - acc: 0.4971\n",
      "Epoch 60/100\n",
      "100000/100000 [==============================] - 19s 190us/sample - loss: 0.6932 - acc: 0.4983\n",
      "Epoch 61/100\n",
      "100000/100000 [==============================] - 10s 99us/sample - loss: 0.6932 - acc: 0.4998\n",
      "Epoch 62/100\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.6932 - acc: 0.4985\n",
      "Epoch 63/100\n",
      "100000/100000 [==============================] - 10s 101us/sample - loss: 0.6932 - acc: 0.4994\n",
      "Epoch 64/100\n",
      "100000/100000 [==============================] - 10s 98us/sample - loss: 0.6932 - acc: 0.4977\n",
      "Epoch 65/100\n",
      "100000/100000 [==============================] - 10s 100us/sample - loss: 0.6932 - acc: 0.4993\n",
      "Epoch 66/100\n",
      "100000/100000 [==============================] - 10s 99us/sample - loss: 0.6932 - acc: 0.5003\n",
      "Epoch 67/100\n",
      "100000/100000 [==============================] - 10s 97us/sample - loss: 0.6932 - acc: 0.5007\n",
      "Epoch 68/100\n",
      "100000/100000 [==============================] - 10s 98us/sample - loss: 0.6932 - acc: 0.4981\n",
      "Epoch 69/100\n",
      "100000/100000 [==============================] - 10s 103us/sample - loss: 0.6932 - acc: 0.5021\n",
      "Epoch 70/100\n",
      "100000/100000 [==============================] - 10s 100us/sample - loss: 0.6932 - acc: 0.5003\n",
      "Epoch 71/100\n",
      "100000/100000 [==============================] - 8s 84us/sample - loss: 0.6932 - acc: 0.4977\n",
      "Epoch 72/100\n",
      "100000/100000 [==============================] - 8s 82us/sample - loss: 0.6932 - acc: 0.5026\n",
      "Epoch 73/100\n",
      "100000/100000 [==============================] - 9s 89us/sample - loss: 0.6932 - acc: 0.4988\n",
      "Epoch 74/100\n",
      "100000/100000 [==============================] - 10s 95us/sample - loss: 0.6932 - acc: 0.4965\n",
      "Epoch 75/100\n",
      "100000/100000 [==============================] - 10s 98us/sample - loss: 0.6931 - acc: 0.5016\n",
      "Epoch 76/100\n",
      "100000/100000 [==============================] - 9s 88us/sample - loss: 0.6932 - acc: 0.4978\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 73200/100000 [====================>.........] - ETA: 2s - loss: 0.6932 - acc: 0.4977"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-72ec9baa9b6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/BNN_env_python3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.virtualenvs/BNN_env_python3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/BNN_env_python3.6/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/.virtualenvs/BNN_env_python3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "history = model.fit(X,Y,epochs=100,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49742004]], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 139, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 139, 16)           80        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_18 (Averag (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 369\n",
      "Trainable params: 369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100000/100000 [==============================] - 11s 106us/sample - loss: 0.5643 - acc: 0.7218\n",
      "Epoch 2/100\n",
      "100000/100000 [==============================] - 13s 127us/sample - loss: 0.5113 - acc: 0.7538\n",
      "Epoch 3/100\n",
      "100000/100000 [==============================] - 13s 130us/sample - loss: 0.4937 - acc: 0.7670\n",
      "Epoch 4/100\n",
      "100000/100000 [==============================] - 11s 110us/sample - loss: 0.4842 - acc: 0.7736\n",
      "Epoch 5/100\n",
      "100000/100000 [==============================] - 14s 141us/sample - loss: 0.4797 - acc: 0.7760\n",
      "Epoch 6/100\n",
      "100000/100000 [==============================] - 13s 131us/sample - loss: 0.4775 - acc: 0.7779\n",
      "Epoch 7/100\n",
      "100000/100000 [==============================] - 11s 107us/sample - loss: 0.4759 - acc: 0.7793\n",
      "Epoch 8/100\n",
      "100000/100000 [==============================] - 13s 128us/sample - loss: 0.4746 - acc: 0.7799\n",
      "Epoch 9/100\n",
      "100000/100000 [==============================] - 10s 99us/sample - loss: 0.4735 - acc: 0.7797\n",
      "Epoch 10/100\n",
      "100000/100000 [==============================] - 11s 105us/sample - loss: 0.4726 - acc: 0.7812\n",
      "Epoch 11/100\n",
      "100000/100000 [==============================] - 11s 114us/sample - loss: 0.4713 - acc: 0.7819\n",
      "Epoch 12/100\n",
      "100000/100000 [==============================] - 12s 120us/sample - loss: 0.4707 - acc: 0.7826\n",
      "Epoch 13/100\n",
      "100000/100000 [==============================] - 12s 117us/sample - loss: 0.4696 - acc: 0.7831\n",
      "Epoch 14/100\n",
      "100000/100000 [==============================] - 12s 116us/sample - loss: 0.4685 - acc: 0.7844\n",
      "Epoch 15/100\n",
      "100000/100000 [==============================] - 11s 111us/sample - loss: 0.4676 - acc: 0.7854\n",
      "Epoch 16/100\n",
      "100000/100000 [==============================] - 11s 113us/sample - loss: 0.4664 - acc: 0.7862\n",
      "Epoch 17/100\n",
      "100000/100000 [==============================] - 13s 132us/sample - loss: 0.4658 - acc: 0.7865\n",
      "Epoch 18/100\n",
      "100000/100000 [==============================] - 11s 106us/sample - loss: 0.4650 - acc: 0.7860\n",
      "Epoch 19/100\n",
      "100000/100000 [==============================] - 10s 101us/sample - loss: 0.4643 - acc: 0.7872\n",
      "Epoch 20/100\n",
      "100000/100000 [==============================] - 10s 100us/sample - loss: 0.4644 - acc: 0.7869\n",
      "Epoch 21/100\n",
      "100000/100000 [==============================] - 11s 110us/sample - loss: 0.4636 - acc: 0.7872\n",
      "Epoch 22/100\n",
      "100000/100000 [==============================] - 10s 101us/sample - loss: 0.4634 - acc: 0.7880\n",
      "Epoch 23/100\n",
      "100000/100000 [==============================] - 11s 115us/sample - loss: 0.4629 - acc: 0.7880\n",
      "Epoch 24/100\n",
      "100000/100000 [==============================] - 12s 116us/sample - loss: 0.4626 - acc: 0.7881\n",
      "Epoch 25/100\n",
      "100000/100000 [==============================] - 12s 120us/sample - loss: 0.4619 - acc: 0.7887\n",
      "Epoch 26/100\n",
      " 65536/100000 [==================>...........] - ETA: 3s - loss: 0.4626 - acc: 0.7866"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-bbb1d75326b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/BNN_env_python3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.virtualenvs/BNN_env_python3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mbatch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/BNN_env_python3.6/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;31m# will be handled by on_epoch_end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/BNN_env_python3.6/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/BNN_env_python3.6/lib/python3.6/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "history = model.fit(X,Y,epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BNN_env_python3.6",
   "language": "python",
   "name": "bnn_env_python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
