{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import energyflow\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numdata = 200000\n",
    "numvalid = 10000\n",
    "numtrain = numdata - numvalid\n",
    "X, Y = energyflow.datasets.qg_jets.load(num_data=numdata, generator='pythia', pad=True, with_bc=False, cache_dir='~/.energyflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess by centering jets and normalizing pts\n",
    "for x in X:\n",
    "    mask = x[:,0] > 0\n",
    "    yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "    x[mask,1:3] -= yphi_avg\n",
    "    x[mask,0] /= x[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess PIDs so they are O(1) or less\n",
    "X[:,:,3] = X[:,:,3] / 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep 80 hardest particles\n",
    "import random\n",
    "nparticles = 80\n",
    "X_clipped = np.array([np.flip(x[x[:,0].argsort()][-nparticles:],axis=0) for x in X])\n",
    "for x_clipped in X_clipped:\n",
    "    np.random.shuffle(x_clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_clipped[:numtrain]\n",
    "X_valid = X_clipped[numtrain:]\n",
    "Y_train = Y[:numtrain]\n",
    "Y_valid = Y[numtrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jack/.virtualenvs/BNN_env_python3.6/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 80, 4)             0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 80, 16)            80        \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 369\n",
      "Trainable params: 369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(nparticles,4))\n",
    "layer = keras.layers.Conv1D(16,1,padding=\"same\",activation=\"relu\")(inputs)\n",
    "layer = keras.layers.GlobalAveragePooling1D()(layer)\n",
    "layer = keras.layers.Lambda(lambda x: x * np.sqrt(nparticles))(layer)    # Make variance after sum the same as before sum\n",
    "layer = keras.layers.Dense(16,activation=\"relu\")(layer)\n",
    "output = keras.layers.Dense(1,activation=\"sigmoid\")(layer)\n",
    "regular_model = keras.Model(inputs=inputs, outputs=output)\n",
    "regular_model.summary()\n",
    "\n",
    "regular_model.compile(optimizer=keras.optimizers.Adam(),\n",
    "             loss = 'binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jack/.virtualenvs/BNN_env_python3.6/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "190000/190000 [==============================] - 21s 109us/sample - loss: 0.5019 - acc: 0.7595\n",
      "Epoch 2/10\n",
      "190000/190000 [==============================] - 21s 112us/sample - loss: 0.4694 - acc: 0.7825\n",
      "Epoch 3/10\n",
      "190000/190000 [==============================] - 24s 128us/sample - loss: 0.4645 - acc: 0.7860\n",
      "Epoch 4/10\n",
      "190000/190000 [==============================] - 28s 147us/sample - loss: 0.4610 - acc: 0.7889\n",
      "Epoch 5/10\n",
      "190000/190000 [==============================] - 21s 112us/sample - loss: 0.4594 - acc: 0.7902\n",
      "Epoch 6/10\n",
      "190000/190000 [==============================] - 23s 119us/sample - loss: 0.4585 - acc: 0.7897\n",
      "Epoch 7/10\n",
      "190000/190000 [==============================] - 29s 152us/sample - loss: 0.4571 - acc: 0.7901\n",
      "Epoch 8/10\n",
      "190000/190000 [==============================] - 25s 129us/sample - loss: 0.4562 - acc: 0.7913\n",
      "Epoch 9/10\n",
      "190000/190000 [==============================] - 22s 117us/sample - loss: 0.4555 - acc: 0.7916\n",
      "Epoch 10/10\n",
      "190000/190000 [==============================] - 23s 124us/sample - loss: 0.4549 - acc: 0.7920\n"
     ]
    }
   ],
   "source": [
    "history = regular_model.fit(X_train,Y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BNN\n",
    "\n",
    "### 1. Same architecture as regular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80, 4)             0         \n",
      "_________________________________________________________________\n",
      "1_Conv_1 (Conv1DFlipout)     (None, 80, 16)            144       \n",
      "_________________________________________________________________\n",
      "2_Sum (GlobalAveragePooling1 (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "3_Dense_1 (DenseFlipout)     (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "4_Dense_logit (DenseFlipout) (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/jack/.virtualenvs/BNN_env_python3.6/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "labels = tf.placeholder(tf.float32,shape=[None,1])\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(nparticles,4))\n",
    "layer = tfp.layers.Convolution1DFlipout(16,1,padding=\"same\",activation=\"relu\",name=\"1_Conv_1\")(inputs)\n",
    "layer = keras.layers.GlobalAveragePooling1D(name=\"2_Sum\")(layer)\n",
    "layer = keras.layers.Lambda(lambda x: x * np.sqrt(nparticles))(layer)\n",
    "layer = tfp.layers.DenseFlipout(16,activation=\"relu\",name=\"3_Dense_1\")(layer)\n",
    "output = tfp.layers.DenseFlipout(1,name=\"4_Dense_logit\")(layer)\n",
    "model = keras.Model(inputs=inputs, outputs=output)\n",
    "model.summary()\n",
    "\n",
    "inputs = tf.placeholder(tf.float32,shape=[None,nparticles,4],name=\"inputs\")\n",
    "logits = model(inputs)\n",
    "\n",
    "labels_distribution = tfp.distributions.Bernoulli(logits=logits)\n",
    "\n",
    "neg_log_likelihood = -tf.reduce_mean(labels_distribution.log_prob(labels),axis=-1)\n",
    "kl = sum(model.losses) / len(X_train)\n",
    "elbo_loss = neg_log_likelihood + kl\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "train_op = optimizer.minimize(elbo_loss)\n",
    "\n",
    "predictions = tf.round(tf.sigmoid(logits))\n",
    "accuracy, accuracy_update_op = tf.metrics.accuracy(labels=labels, predictions=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Loss: 0.541010 Accuracy: 0.704\n",
      "Epoch:   1 Loss: 0.494689 Accuracy: 0.743\n",
      "Epoch:   2 Loss: 0.479570 Accuracy: 0.756\n",
      "Epoch:   3 Loss: 0.473701 Accuracy: 0.763\n",
      "Epoch:   4 Loss: 0.470408 Accuracy: 0.768\n",
      "Epoch:   5 Loss: 0.468528 Accuracy: 0.772\n",
      "Epoch:   6 Loss: 0.466568 Accuracy: 0.774\n",
      "Epoch:   7 Loss: 0.465176 Accuracy: 0.776\n",
      "Epoch:   8 Loss: 0.463950 Accuracy: 0.778\n",
      "Epoch:   9 Loss: 0.462762 Accuracy: 0.779\n"
     ]
    }
   ],
   "source": [
    "epochs = 10 #number of training steps to run\n",
    "max_step = int(len(X_train)/batch_size)\n",
    "\n",
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                   tf.local_variables_initializer())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "# Run the training loop.\n",
    "        for epoch in range(epochs):\n",
    "            loss_list = []\n",
    "            acc_list = []\n",
    "            for step in range(max_step):\n",
    "                imin = step*batch_size\n",
    "                x_train = X_train[imin:imin+batch_size]\n",
    "                y_train = Y_train[imin:imin+batch_size].reshape(batch_size,1)\n",
    "\n",
    "                _ = sess.run([train_op, accuracy_update_op],\n",
    "                             feed_dict={inputs: x_train,\n",
    "                                        labels: y_train})\n",
    "            \n",
    "                loss_value, accuracy_value = sess.run([elbo_loss, accuracy],\n",
    "                                                      feed_dict={inputs: x_train,\n",
    "                                                                 labels: y_train})\n",
    "                loss_list.append(loss_value)\n",
    "                acc_list.append(accuracy_value)\n",
    "\n",
    "            print(\"Epoch: {:>3d} Loss: {:.6f} Accuracy: {:.3f}\".format(epoch,\n",
    "                                                                       np.mean(loss_list),\n",
    "                                                                       np.mean(acc_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bigger architecture\n",
    "\n",
    "#### Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 80, 4)             0         \n",
      "_________________________________________________________________\n",
      "1_Conv_1 (Conv1DFlipout)     (None, 80, 64)            576       \n",
      "_________________________________________________________________\n",
      "2_Conv_2 (Conv1DFlipout)     (None, 80, 64)            8256      \n",
      "_________________________________________________________________\n",
      "3_Sum (GlobalAveragePooling1 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "4_Dense_1 (DenseFlipout)     (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "5_Dense_2 (DenseFlipout)     (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "6_Dense_logit (DenseFlipout) (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 25,473\n",
      "Trainable params: 25,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "labels = tf.placeholder(tf.float32,shape=[None,1])\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(nparticles,4))\n",
    "layer = tfp.layers.Convolution1DFlipout(64,1,padding=\"same\",activation=\"relu\",name=\"1_Conv_1\")(inputs)\n",
    "layer = tfp.layers.Convolution1DFlipout(64,1,padding=\"same\",activation=\"relu\",name=\"2_Conv_2\")(layer)\n",
    "layer = keras.layers.GlobalAveragePooling1D(name=\"3_Sum\")(layer)\n",
    "layer = keras.layers.Lambda(lambda x: x * np.sqrt(nparticles))(layer)\n",
    "layer = tfp.layers.DenseFlipout(64,activation=\"relu\",name=\"4_Dense_1\")(layer)\n",
    "layer = tfp.layers.DenseFlipout(64,activation=\"relu\",name=\"5_Dense_2\")(layer)\n",
    "output = tfp.layers.DenseFlipout(1,name=\"6_Dense_logit\")(layer)\n",
    "model = keras.Model(inputs=inputs, outputs=output)\n",
    "model.summary()\n",
    "\n",
    "inputs = tf.placeholder(tf.float32,shape=[None,nparticles,4],name=\"inputs\")\n",
    "logits = model(inputs)\n",
    "\n",
    "labels_distribution = tfp.distributions.Bernoulli(logits=logits)\n",
    "\n",
    "neg_log_likelihood = -tf.reduce_mean(labels_distribution.log_prob(labels),axis=-1)\n",
    "kl = sum(model.losses) / len(X_train)\n",
    "elbo_loss = neg_log_likelihood + kl\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "train_op = optimizer.minimize(elbo_loss)\n",
    "\n",
    "predictions = tf.round(tf.sigmoid(logits))\n",
    "accuracy, accuracy_update_op = tf.metrics.accuracy(labels=labels, predictions=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Loss: 0.626456 Accuracy: 0.718\n",
      "Epoch:   1 Loss: 0.561848 Accuracy: 0.765\n",
      "Epoch:   2 Loss: 0.535312 Accuracy: 0.772\n",
      "Epoch:   3 Loss: 0.517190 Accuracy: 0.776\n",
      "Epoch:   4 Loss: 0.505375 Accuracy: 0.779\n",
      "Epoch:   5 Loss: 0.495442 Accuracy: 0.781\n",
      "Epoch:   6 Loss: 0.488534 Accuracy: 0.783\n",
      "Epoch:   7 Loss: 0.482497 Accuracy: 0.784\n",
      "Epoch:   8 Loss: 0.478142 Accuracy: 0.785\n",
      "Epoch:   9 Loss: 0.473924 Accuracy: 0.786\n"
     ]
    }
   ],
   "source": [
    "epochs = 10 #number of training steps to run\n",
    "max_step = int(len(X_train)/batch_size)\n",
    "\n",
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                   tf.local_variables_initializer())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "# Run the training loop.\n",
    "        for epoch in range(epochs):\n",
    "            loss_list = []\n",
    "            acc_list = []\n",
    "            for step in range(max_step):\n",
    "                imin = step*batch_size\n",
    "                x_train = X_train[imin:imin+batch_size]\n",
    "                y_train = Y_train[imin:imin+batch_size].reshape(batch_size,1)\n",
    "\n",
    "                _ = sess.run([train_op, accuracy_update_op],\n",
    "                             feed_dict={inputs: x_train,\n",
    "                                        labels: y_train})\n",
    "            \n",
    "                loss_value, accuracy_value = sess.run([elbo_loss, accuracy],\n",
    "                                                      feed_dict={inputs: x_train,\n",
    "                                                                 labels: y_train})\n",
    "                loss_list.append(loss_value)\n",
    "                acc_list.append(accuracy_value)\n",
    "\n",
    "            print(\"Epoch: {:>3d} Loss: {:.6f} Accuracy: {:.3f}\".format(epoch,\n",
    "                                                                       np.mean(loss_list),\n",
    "                                                                       np.mean(acc_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BNN_env_python3.6",
   "language": "python",
   "name": "bnn_env_python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
