{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import energyflow\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = energyflow.datasets.qg_jets.load(num_data=100000, generator='pythia', pad=True, with_bc=False, cache_dir='~/.energyflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess by centering jets and normalizing pts\n",
    "for x in X:\n",
    "    mask = x[:,0] > 0\n",
    "    yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "    x[mask,1:3] -= yphi_avg\n",
    "    x[mask,0] /= x[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess PIDs so they are O(1) or less\n",
    "X[:,:,3] = X[:,:,3] / 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparticles = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (c1): Conv1d(4, 16, kernel_size=(1,), stride=(1,))\n",
      "  (p1): AvgPool1d(kernel_size=(139,), stride=(139,), padding=(0,))\n",
      "  (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.c1 = nn.Conv1d(4, 16, 1)\n",
    "        self.p1 = nn.AvgPool1d(nparticles)\n",
    "        self.fc1 = nn.Linear(16, 16)\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.c1(x))\n",
    "        x = self.p1(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_torch = torch.tensor(X, dtype=torch.float).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_torch = torch.tensor(Y, dtype=torch.float).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QGDataset(Dataset):\n",
    "    \"\"\"Quark/Gluon dataset from energyflow\"\"\"\n",
    "\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QGDataset(X_torch, Y_torch)\n",
    "dataloader = DataLoader(dataset, batch_size=1,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/smsharma/.conda/envs/Lensing-PowerSpectra/lib/python3.6/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.678\n",
      "[1,  4000] loss: 0.582\n",
      "[1,  6000] loss: 0.556\n",
      "[1,  8000] loss: 0.541\n",
      "[1, 10000] loss: 0.542\n",
      "[1, 12000] loss: 0.530\n",
      "[1, 14000] loss: 0.532\n",
      "[1, 16000] loss: 0.523\n",
      "[1, 18000] loss: 0.511\n",
      "[1, 20000] loss: 0.513\n",
      "[2,  2000] loss: 0.505\n",
      "[2,  4000] loss: 0.500\n",
      "[2,  6000] loss: 0.499\n",
      "[2,  8000] loss: 0.487\n",
      "[2, 10000] loss: 0.492\n",
      "[2, 12000] loss: 0.487\n",
      "[2, 14000] loss: 0.496\n",
      "[2, 16000] loss: 0.487\n",
      "[2, 18000] loss: 0.484\n",
      "[2, 20000] loss: 0.490\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # geat the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_test = QGDataset(X_torch[:1000], Y_torch[:1000])\n",
    "# dataloader_test = DataLoader(dataset_test, batch_size=5,\n",
    "#                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(net, data_x, data_y):\n",
    "    # data_x and data_y are numpy matrices\n",
    "    X = torch.Tensor(data_x)\n",
    "    Y = torch.ByteTensor(data_y)   # a Tensor of 0s and 1s\n",
    "    output = net(X)            # a Tensor of floats\n",
    "    pred_y = output >= 0.5       # a Tensor of 0s and 1s\n",
    "    num_correct = torch.sum(Y==pred_y)  # a Tensor\n",
    "    acc = (num_correct.item() * 100.0 / len(data_y))  # scalar\n",
    "    print('Accuracy: %d %%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77 %\n"
     ]
    }
   ],
   "source": [
    "model_accuracy(net, X_torch, Y_torch.byte())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "16\n",
      "256\n",
      "16\n",
      "16\n",
      "1\n",
      "369\n"
     ]
    }
   ],
   "source": [
    "running_sum = 0\n",
    "for p in net.parameters():\n",
    "    if p.requires_grad:\n",
    "        running_sum += p.numel()\n",
    "        print(p.numel())\n",
    "print(running_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1                [-1, 16, 1]              80\n",
      "         AvgPool1d-2                [-1, 16, 1]               0\n",
      "            Linear-3                   [-1, 16]             272\n",
      "            Linear-4                    [-1, 1]              17\n",
      "================================================================\n",
      "Total params: 369\n",
      "Trainable params: 369\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(net, input_size=(4, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to BNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "from pyro.distributions import Bernoulli, Normal\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_data, y_data):\n",
    "    \n",
    "    c1w_prior = Normal(loc=torch.zeros_like(net.c1.weight), scale=torch.ones_like(net.c1.weight))\n",
    "    c1b_prior = Normal(loc=torch.zeros_like(net.c1.bias), scale=torch.ones_like(net.c1.bias))\n",
    "\n",
    "    fc1w_prior = Normal(loc=torch.zeros_like(net.fc1.weight), scale=torch.ones_like(net.fc1.weight))\n",
    "    fc1b_prior = Normal(loc=torch.zeros_like(net.fc1.bias), scale=torch.ones_like(net.fc1.bias))\n",
    "\n",
    "    fc2w_prior = Normal(loc=torch.zeros_like(net.fc2.weight), scale=torch.ones_like(net.fc2.weight))\n",
    "    fc2b_prior = Normal(loc=torch.zeros_like(net.fc2.bias), scale=torch.ones_like(net.fc2.bias))\n",
    "    \n",
    "    priors = {'c1.weight': c1w_prior, 'c1.bias': c1b_prior,  'fc1.weight': fc1w_prior, 'fc1.bias': fc1b_prior,  'fc2.weight': fc2w_prior, 'fc2.bias': fc2b_prior}\n",
    "    \n",
    "    # lift module parameters to random variables sampled from the priors\n",
    "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
    "    lifted_model = lifted_module()\n",
    "    \n",
    "    model_out = lifted_model(x_data)\n",
    "    \n",
    "    pyro.sample(\"obs\", Bernoulli(logits=model_out), obs=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide = AutoDiagonalNormal(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_optim = Adam({\"lr\": 0.001})\n",
    "svi = SVI(model, guide, torch_optim, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test to make sure everything working\n",
    "# inputs, labels = next(iter(dataloader))\n",
    "# svi.step(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.930\n",
      "[1,   400] loss: 0.929\n",
      "[1,   600] loss: 1.028\n",
      "[1,   800] loss: 0.999\n",
      "[1,  1000] loss: 1.000\n",
      "[1,  1200] loss: 0.986\n",
      "[1,  1400] loss: 0.906\n",
      "[1,  1600] loss: 0.904\n",
      "[1,  1800] loss: 0.893\n",
      "[1,  2000] loss: 0.952\n",
      "[1,  2200] loss: 1.043\n",
      "[1,  2400] loss: 0.909\n",
      "[1,  2600] loss: 1.079\n",
      "[1,  2800] loss: 1.022\n",
      "[1,  3000] loss: 1.004\n",
      "[1,  3200] loss: 0.942\n",
      "[1,  3400] loss: 0.996\n",
      "[1,  3600] loss: 0.952\n",
      "[1,  3800] loss: 0.930\n",
      "[1,  4000] loss: 0.986\n",
      "[1,  4200] loss: 1.042\n",
      "[1,  4400] loss: 1.007\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # geat the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        loss = svi.step(inputs, labels)\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
